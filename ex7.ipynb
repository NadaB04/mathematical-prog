{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQpnP1AYu95c",
        "outputId": "57460a0b-0d72-4ad1-f891-7248e42557f0"
      },
      "source": [
        "stations = {251691:\"Beer Sheva\", 2496260:\"Ortal\", 120530:\"Technion\", 245782:\"Jerusalem\", 211890:\"Tsfat\", 133871:\"Kfar Saba\"}\n",
        "stats = [\\\n",
        "\t(251691,'01/01/2018', 19.7), \t(251691,'04/01/2018', 2.4), \t(251691,'05/01/2018', 37.7), \t(251691,'06/01/2018', 3.7), \t(251691,'14/01/2018', 10.7), \t(251691,'18/01/2018', 15.7), \t(251691,'19/01/2018', 2.6), \t(251691,'22/01/2018', 0.3), \t(251691,'25/01/2018', 1.1), \t(251691,'26/01/2018', 5.9), \t(251691,'27/01/2018', 14.5), \t(251691,'29/01/2018', 1), \t(251691,'12/02/2018', 6.6), \t(251691,'13/02/2018', 5.2), \t(251691,'16/02/2018', 11), \t(251691,'17/02/2018', 3.9), \t(251691,'21/02/2018', 3.5), \t(251691,'22/02/2018', 0.5), \t(251691,'23/02/2018', 0.1), \t(251691,'25/02/2018', 2.7), \t(251691,'26/02/2018', 6.4), \t(251691,'29/03/2018', 2.5), \t(251691,'22/04/2018', 1.6), \t(251691,'24/04/2018', 0.1), \t(251691,'25/04/2018', 7.2), \t(251691,'26/04/2018', 0.9), \t(251691,'07/05/2018', 0.2), \t(251691,'13/06/2018', 1.9), \t(251691,'25/10/2018', 6.5), \t(251691,'04/11/2018', 4.1), \t(251691,'05/11/2018', 1.9), \t(251691,'06/11/2018', 0.2), \t(251691,'09/11/2018', 0.4), \t(251691,'14/11/2018', 0.4), \t(251691,'22/11/2018', 0.5), \t(251691,'23/11/2018', 27.4), \t(251691,'24/11/2018', 0.4), \t(251691,'06/12/2018', 1.1), \t(251691,'12/12/2018', 0.7), \t(251691,'13/12/2018', 1.4), \t(251691,'19/12/2018', 1), \t(251691,'20/12/2018', 5), \t(251691,'21/12/2018', 0.1), \t(251691,'28/12/2018', 0.7), \t(251691,'29/12/2018', 2.5), \t(251691,'30/12/2018', 4.9),   (120530,'01/01/2018', 22.9), \t(120530,'02/01/2018', 1.4), \t(120530,'03/01/2018', 1.6), \t(120530,'04/01/2018', 71), \t(120530,'05/01/2018', 21.6), \t(120530,'06/01/2018', 0.4), \t(120530,'13/01/2018', 12.9), \t(120530,'14/01/2018', 1.8), \t(120530,'16/01/2018', 1.4), \t(120530,'17/01/2018', 12.9), \t(120530,'18/01/2018', 23.6), \t(120530,'19/01/2018', 0.1), \t(120530,'22/01/2018', 11.1), \t(120530,'23/01/2018', 8.6), \t(120530,'24/01/2018', 16.7), \t(120530,'25/01/2018', 49.1), \t(120530,'26/01/2018', 23), \t(120530,'27/01/2018', 5.3), \t(120530,'29/01/2018', 1.3), \t(120530,'11/02/2018', 9.7), \t(120530,'12/02/2018', 32.1), \t(120530,'13/02/2018', 8.6), \t(120530,'16/02/2018', 19.3), \t(120530,'17/02/2018', 41.4), \t(120530,'21/02/2018', 14.9), \t(120530,'25/02/2018', 3.1), \t(120530,'26/02/2018', 24.4), \t(120530,'24/03/2018', 0.1), \t(120530,'27/03/2018', 0.9), \t(120530,'29/03/2018', 2.2), \t(120530,'30/03/2018', 2.9), \t(120530,'09/04/2018', 7.5), \t(120530,'10/04/2018', 6), \t(120530,'11/04/2018', 0.1), \t(120530,'21/04/2018', 1.7), \t(120530,'24/04/2018', 0.2), \t(120530,'25/04/2018', 19.1), \t(120530,'26/04/2018', 4.7), \t(120530,'06/05/2018', 0.6), \t(120530,'07/05/2018', 6.9), \t(120530,'08/05/2018', 5.8), \t(120530,'11/05/2018', 0.1), \t(120530,'13/05/2018', 2), \t(120530,'30/05/2018', 3.4), \t(120530,'31/05/2018', 2), \t(120530,'11/06/2018', 0.5), \t(120530,'12/06/2018', 1.7), \t(120530,'07/09/2018', 1.1), \t(120530,'21/10/2018', 13.5), \t(120530,'25/10/2018', 15.7), \t(120530,'04/11/2018', 5), \t(120530,'05/11/2018', 4.1), \t(120530,'06/11/2018', 0.2), \t(120530,'10/11/2018', 8.4), \t(120530,'14/11/2018', 4.8), \t(120530,'15/11/2018', 0.5), \t(120530,'16/11/2018', 0.7), \t(120530,'22/11/2018', 34.4), \t(120530,'23/11/2018', 4.5), \t(120530,'24/11/2018', 15.3), \t(120530,'25/11/2018', 0.3), \t(120530,'30/11/2018', 7), \t(120530,'01/12/2018', 21.8), \t(120530,'03/12/2018', 0.9), \t(120530,'04/12/2018', 1.3), \t(120530,'05/12/2018', 25.3), \t(120530,'06/12/2018', 38.2), \t(120530,'07/12/2018', 33.4), \t(120530,'08/12/2018', 2.8), \t(120530,'12/12/2018', 6.9), \t(120530,'17/12/2018', 26.8), \t(120530,'18/12/2018', 15.6), \t(120530,'19/12/2018', 27), \t(120530,'20/12/2018', 0.8), \t(120530,'22/12/2018', 0.7), \t(120530,'26/12/2018', 13.2), \t(120530,'27/12/2018', 11.6), \t(120530,'28/12/2018', 5.3), \t(120530,'29/12/2018', 20), \t(120530,'30/12/2018', 4), \t(120530,'31/12/2018', 6.3),   (245782,'01/01/2018', 17.8), \t(245782,'02/01/2018', 1), \t(245782,'04/01/2018', 6.6), \t(245782,'05/01/2018', 56.6), \t(245782,'06/01/2018', 1.4), \t(245782,'13/01/2018', 2.6), \t(245782,'14/01/2018', 17.2), \t(245782,'15/01/2018', 0.5), \t(245782,'17/01/2018', 5.1), \t(245782,'18/01/2018', 26.5), \t(245782,'19/01/2018', 5), \t(245782,'22/01/2018', 1.8), \t(245782,'23/01/2018', 1.3), \t(245782,'24/01/2018', 3.4), \t(245782,'25/01/2018', 7.4), \t(245782,'26/01/2018', 21.9), \t(245782,'27/01/2018', 0.5), \t(245782,'28/01/2018', 0.2), \t(245782,'29/01/2018', 0.2), \t(245782,'12/02/2018', 10.6), \t(245782,'13/02/2018', 8.2), \t(245782,'16/02/2018', 6.3), \t(245782,'17/02/2018', 29.4), \t(245782,'18/02/2018', 0.1), \t(245782,'21/02/2018', 3.3), \t(245782,'25/02/2018', 1.6), \t(245782,'26/02/2018', 4.9), \t(245782,'23/03/2018', 0.1), \t(245782,'24/03/2018', 0.1), \t(245782,'27/03/2018', 1.3), \t(245782,'28/03/2018', 1.3), \t(245782,'29/03/2018', 5.2), \t(245782,'30/03/2018', 1), \t(245782,'09/04/2018', 0.1), \t(245782,'10/04/2018', 18.6), \t(245782,'21/04/2018', 8.8), \t(245782,'24/04/2018', 0.1), \t(245782,'25/04/2018', 17.3), \t(245782,'26/04/2018', 20.9), \t(245782,'07/05/2018', 0.7), \t(245782,'11/05/2018', 1.2), \t(245782,'12/05/2018', 0.1), \t(245782,'13/06/2018', 0.1), \t(245782,'07/09/2018', 0.8), \t(245782,'22/10/2018', 0.1), \t(245782,'25/10/2018', 17.7), \t(245782,'04/11/2018', 4.1), \t(245782,'05/11/2018', 0.4), \t(245782,'07/11/2018', 0.8), \t(245782,'09/11/2018', 1.3), \t(245782,'12/11/2018', 0.1), \t(245782,'13/11/2018', 0.2), \t(245782,'14/11/2018', 1.7), \t(245782,'15/11/2018', 2.8), \t(245782,'16/11/2018', 5.2), \t(245782,'22/11/2018', 1.1), \t(245782,'23/11/2018', 22.1), \t(245782,'24/11/2018', 0.2), \t(245782,'25/11/2018', 0.1), \t(245782,'06/12/2018', 47.2), \t(245782,'07/12/2018', 15.3), \t(245782,'08/12/2018', 12), \t(245782,'12/12/2018', 2.2), \t(245782,'17/12/2018', 5), \t(245782,'19/12/2018', 18.7), \t(245782,'20/12/2018', 16.2), \t(245782,'21/12/2018', 0.9), \t(245782,'27/12/2018', 46.7), \t(245782,'28/12/2018', 1), \t(245782,'29/12/2018', 1.1), \t(245782,'30/12/2018', 10) \\\n",
        "]\n",
        "def calculate_annual_stats(data, year):\n",
        "  stations_rain_days = []\n",
        "  stations = []\n",
        "  for tup in data:\n",
        "    if tup[0] not in stations and tup[1].split(\"/\")[2] == year:\n",
        "      stations.append(tup[0])\n",
        "      stations_rain_days.append((tup[0], tup[2], 1)) #מאתחל עם הנתונים של הטאפ\n",
        "    elif tup[1].split(\"/\")[2] == year:\n",
        "      for i in range(len(stations_rain_days)): #מוצא את התחנה\n",
        "        if stations_rain_days[i][0] == tup[0]:\n",
        "          stations_rain_days[i] = (tup[0], stations_rain_days[i][1] + tup[2], stations_rain_days[i][2] +1)\n",
        "  return stations_rain_days\n",
        "\n",
        "def print_annual_data(data, stations):\n",
        "  \n",
        "  years = []\n",
        "  all_years_stat = []\n",
        "  for station_code in stations.keys():\n",
        "    for tup in data:\n",
        "      if tup[0] == station_code and tup[1].split(\"/\")[2] not in years:\n",
        "        years.append(tup[1].split(\"/\")[2])\n",
        "  for year in years:\n",
        "    print(f'Annual stats for: {year}')\n",
        "    annual_stats = []    \n",
        "    annual_stats = calculate_annual_stats(data, str(year))\n",
        "    for station_code in stations.keys():\n",
        "      for stat in annual_stats:\n",
        "        if stat[0] == station_code:\n",
        "          print(f'{stations[station_code]} {stat[1]} {stat[2]}')\n",
        "    \n",
        "\n",
        "\n",
        "print_annual_data(stats, stations)\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Annual stats for: 2018\n",
            "Beer Sheva 228.79999999999995 46\n",
            "Technion 885.9999999999998 81\n",
            "Jerusalem 553.3000000000002 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdRxRdHOvrvA",
        "outputId": "9b127582-965b-429f-b8f4-b6c0bc359884"
      },
      "source": [
        "WORD_BANK = ['nadav', 'aa', 'davar']\n",
        "\n",
        "\n",
        "def max_len(words):\n",
        "  maxlen = -1\n",
        "  for word in words:\n",
        "    if len(word) > maxlen:\n",
        "      maxlen = len(word)\n",
        "\n",
        "  return maxlen\n",
        "\n",
        "def matchingwords(letters):\n",
        "  final_list = []\n",
        "  for word in WORD_BANK:\n",
        "    if hachla([ch for ch in word], letters): #מחזיר אמת אם המילה מורכבת מאותיות הרשימה\n",
        "      final_list.append(word)\n",
        "  return final_list\n",
        "\n",
        "def words_by_len(words):\n",
        "  full_list = []\n",
        "  for i in range(1, (max_len(words)+1), 1):\n",
        "    temp_list = []\n",
        "    for word in words:\n",
        "      if len(word) == i:\n",
        "        temp_list.append(word)\n",
        "    temp_list.sort()\n",
        "    full_list.append(temp_list)\n",
        "\n",
        "  return full_list\n",
        "\n",
        "\n",
        "\n",
        "def hachla(list1, list2):\n",
        "  state = True\n",
        "  for item1 in list1:\n",
        "    if item1 not in list2:\n",
        "      state = False\n",
        "      break\n",
        "\n",
        "  return state\n",
        "\n",
        "\n",
        "def nokfilut(letters):\n",
        "  kfiluit_list = []\n",
        "  for letter in letters:\n",
        "    if ord(letter) < 97:\n",
        "      kfiluit_list.append(chr(ord(letter)+32))\n",
        "    else:\n",
        "      kfiluit_list.append(letter)\n",
        "  letter_set = set(kfiluit_list)\n",
        "  final_letters = []\n",
        "  for letter in letter_set:\n",
        "    final_letters.append(letter)\n",
        "  return final_letters\n",
        "\n",
        "\n",
        "\n",
        "kelet = set(input(\"Letters (Enter to quit): \"))\n",
        "letters = []\n",
        "for ch in kelet:\n",
        "  if (ord(ch) >= 97 and ord(ch) <= 122) or (ord(ch) >= 65 and ord(ch) <= 90):\n",
        "    letters.append(ch)\n",
        "print(letters)\n",
        "letters = nokfilut(letters)\n",
        "print(f'Your Letters: {letters}')\n",
        "full_list = []\n",
        "full_list = words_by_len(matchingwords(letters))\n",
        "for lst in full_list:\n",
        "  if len(lst) > 0:\n",
        "    print(f'{len(lst[0])} letter words: ', end ='')\n",
        "    if len(lst) == 1:\n",
        "      print(lst[0])\n",
        "    else:\n",
        "      for i in range(len(lst)-1):\n",
        "        print(lst[i], end = '')\n",
        "      print(lst[len(lst)-1])\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Letters (Enter to quit): nadv\n",
            "['d', 'a', 'v', 'n']\n",
            "Your Letters: ['d', 'a', 'v', 'n']\n",
            "2 letter words: aa\n",
            "5 letter words: nadav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NorqAJ46s4Qw"
      },
      "source": [
        "מגיש: נדב בנאי\n",
        "ת.ז: 326277910\n",
        "קבוצת תרגול: אלכסנדרה ליטינסקי סימנובסקי"
      ]
    }
  ]
}